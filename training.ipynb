{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T00:34:57.240737Z",
     "iopub.status.busy": "2023-04-30T00:34:57.240294Z",
     "iopub.status.idle": "2023-04-30T00:34:57.254341Z",
     "shell.execute_reply": "2023-04-30T00:34:57.253239Z",
     "shell.execute_reply.started": "2023-04-30T00:34:57.240657Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from externals.utils import set_seed, make_dirs, cfg_init\n",
    "from externals.dataloading import read_image_mask, read_image_mask_downsampling, get_train_valid_dataset, get_transforms, CustomDataset\n",
    "from externals.models import CNN3D_Segformer, Unet3D_Segformer, CNN3D_Unet, CNN3D_MANet, CNN3D_EfficientUnetplusplusb5, CNN3D_SegformerB4\n",
    "from externals.metrics import AverageMeter, calc_fbeta\n",
    "from externals.training_procedures import get_scheduler, scheduler_step, criterion\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T00:35:16.839770Z",
     "iopub.status.busy": "2023-04-30T00:35:16.839272Z",
     "iopub.status.idle": "2023-04-30T00:35:16.856488Z",
     "shell.execute_reply": "2023-04-30T00:35:16.855332Z",
     "shell.execute_reply.started": "2023-04-30T00:35:16.839732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set dataset path\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    is_multiclass = False\n",
    "    \n",
    "    comp_name = 'vesuvius'\n",
    "    comp_dir_path = './input/'\n",
    "    comp_folder_name = 'vesuvius-challenge-ink-detection'\n",
    "    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n",
    "    \n",
    "    exp_name = 'mean_32_channels'\n",
    "    # ============== pred target =============\n",
    "    target_size = 1\n",
    "    # ============== model cfg =============\n",
    "    model_name = '3dcnn_segformer'\n",
    "    # ============== training cfg =============\n",
    "    size = 1024\n",
    "    tile_size = 1024\n",
    "    stride = tile_size // 4\n",
    "    in_chans = 16\n",
    "\n",
    "    train_batch_size = 9\n",
    "    valid_batch_size = train_batch_size\n",
    "    use_amp = True\n",
    "\n",
    "    scheduler = 'GradualWarmupSchedulerV2'\n",
    "    epochs = 30\n",
    "\n",
    "    # adamW warmup\n",
    "    warmup_factor = 10\n",
    "    lr = 1e-4 / warmup_factor\n",
    "    # ============== fold =============\n",
    "    valid_id = 1\n",
    "    # ============== fixed =============\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-6\n",
    "    max_grad_norm = 100\n",
    "    num_workers = 16\n",
    "    seed = 42\n",
    "    # ============== set dataset path =============\n",
    "    print('set dataset path')\n",
    "\n",
    "    outputs_path = f'working/outputs/{comp_name}/{exp_name}/'\n",
    "\n",
    "    submission_dir = outputs_path + 'submissions/'\n",
    "    submission_path = submission_dir + f'submission_{exp_name}.csv'\n",
    "\n",
    "    model_dir = outputs_path + \\\n",
    "        f'{comp_name}-models/'\n",
    "\n",
    "    figures_dir = outputs_path + 'figures/'\n",
    "\n",
    "    log_dir = outputs_path + 'logs/'\n",
    "    log_path = log_dir + f'{exp_name}.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T00:35:16.909594Z",
     "iopub.status.busy": "2023-04-30T00:35:16.909037Z",
     "iopub.status.idle": "2023-04-30T00:35:16.987884Z",
     "shell.execute_reply": "2023-04-30T00:35:16.987163Z",
     "shell.execute_reply.started": "2023-04-30T00:35:16.909555Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_init(CFG)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20491144f65d4451ae0279067270e5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/70.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae720f44917427faa31091af78901e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/179M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nvidia/mit-b3 were not used when initializing SegformerForSemanticSegmentation: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b3 and are newly initialized: ['decode_head.linear_c.3.proj.weight', 'decode_head.batch_norm.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_fuse.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.2.proj.weight', 'decode_head.batch_norm.running_mean', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.3.proj.bias', 'decode_head.batch_norm.weight', 'decode_head.batch_norm.running_var']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b3 and are newly initialized because the shapes did not match:\n",
      "- segformer.encoder.patch_embeddings.0.proj.weight: found shape torch.Size([64, 3, 7, 7]) in the checkpoint and torch.Size([64, 32, 7, 7]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# pick a model from the external folder \n",
    "model = CNN3D_Segformer(CFG) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple model test\n",
    "model(torch.ones(4, 1, 32, 128, 128)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T00:39:47.561606Z",
     "iopub.status.busy": "2023-04-30T00:39:47.560350Z",
     "iopub.status.idle": "2023-04-30T00:39:47.575945Z",
     "shell.execute_reply": "2023-04-30T00:39:47.574899Z",
     "shell.execute_reply.started": "2023-04-30T00:39:47.561568Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    scaler = GradScaler(enabled=CFG.use_amp)\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    for step, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with autocast(CFG.use_amp):\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt):\n",
    "    mask_pred = np.ones(valid_mask_gt.shape)\n",
    "    mask_count = np.zeros(valid_mask_gt.shape)\n",
    "\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    for step, (images, labels) in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels) #undo the stupid sigmoid they put in this implementation\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # make whole mask\n",
    "        y_preds = torch.sigmoid(y_preds).to('cpu').numpy()\n",
    "        start_idx = step*CFG.valid_batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        for i, (x1, y1, x2, y2) in enumerate(valid_xyxys[start_idx:end_idx]):\n",
    "            mask_pred[y1:y2, x1:x2] *= y_preds[i].squeeze(0)\n",
    "            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n",
    "\n",
    "    mask_pred = np.power(mask_pred, 1/mask_count)\n",
    "    mask_pred[mask_pred==1] = 0\n",
    "    return losses.avg, mask_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(CFG):\n",
    "    if CFG.valid_id == None:\n",
    "        train_images, train_masks = get_train_valid_dataset(CFG)\n",
    "    else:\n",
    "        train_images, train_masks, valid_images, valid_masks, valid_xyxys = get_train_valid_dataset(CFG)\n",
    "        valid_xyxys = np.stack(valid_xyxys)\n",
    "        fragment_id = CFG.valid_id\n",
    "\n",
    "        valid_mask_gt = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\n",
    "        valid_mask_gt = valid_mask_gt / 255\n",
    "        pad0 = (CFG.tile_size - valid_mask_gt.shape[0] % CFG.tile_size)\n",
    "        pad1 = (CFG.tile_size - valid_mask_gt.shape[1] % CFG.tile_size)\n",
    "        valid_mask_gt = np.pad(valid_mask_gt, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "        valid_dataset = CustomDataset(\n",
    "            valid_images, CFG, labels=valid_masks, transform=get_transforms(data='valid', cfg=CFG))\n",
    "        valid_loader = DataLoader(valid_dataset,\n",
    "                        batch_size=CFG.valid_batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    train_dataset = CustomDataset(\n",
    "        train_images, CFG, labels=train_masks, transform=get_transforms(data='train', cfg=CFG))\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=CFG.train_batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n",
    "                            )\n",
    "    if CFG.valid_id == None:\n",
    "        return train_loader\n",
    "    else:\n",
    "        return train_loader, valid_loader, valid_xyxys, valid_mask_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_augs(CFG):\n",
    "        # ============== augmentation =============\n",
    "    train_aug_list = [\n",
    "            # A.RandomResizedCrop(\n",
    "            #     size, size, scale=(0.85, 1.0)),\n",
    "            A.Resize(CFG.size, CFG.size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=.5),\n",
    "            A.RandomBrightnessContrast(p=0.25, brightness_limit=.2, contrast_limit=.2),\n",
    "            A.ChannelDropout(channel_drop_range=(1, 2), p = .25),  \n",
    "            A.ShiftScaleRotate(p=0.25),\n",
    "            A.OneOf([\n",
    "                    A.GaussNoise(var_limit=[10, 50]),\n",
    "                    A.GaussianBlur(),\n",
    "                    A.MotionBlur(),\n",
    "                    ], p=0.25),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.25),\n",
    "            A.CoarseDropout(max_holes=1, max_width=int(CFG.size * 0.05), max_height=int(CFG.size * 0.05), \n",
    "                            mask_fill_value=0, p=0.25),\n",
    "            # A.Cutout(max_h_size=int(size * 0.6),\n",
    "            #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "            A.Normalize(\n",
    "                mean= [0] * CFG.in_chans,\n",
    "                std= [1] * CFG.in_chans\n",
    "            ),\n",
    "            ToTensorV2(transpose_mask=True),\n",
    "        ]\n",
    "\n",
    "    valid_aug_list = [\n",
    "            A.Resize(CFG.size, CFG.size),\n",
    "            A.Normalize(\n",
    "                mean= [0] * CFG.in_chans,\n",
    "                std= [1] * CFG.in_chans\n",
    "            ),\n",
    "            ToTensorV2(transpose_mask=True),\n",
    "        ]\n",
    "    return train_aug_list, valid_aug_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_list, valid_aug_list = return_augs(CFG)\n",
    "CFG.train_aug_list, CFG.valid_aug_list = train_aug_list, valid_aug_list\n",
    "cfg_pairs = {value:CFG.__dict__[value] for value in dir(CFG) if value[1] != \"_\"}\n",
    "model_name = f\"{CFG.exp_name}_{CFG.model_name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CNN3D_Segformer(CFG)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "swa_model = AveragedModel(model)\n",
    "swa_start = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T00:39:48.848911Z",
     "iopub.status.busy": "2023-04-30T00:39:48.848504Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "best_counter = 0\n",
    "best_loss = np.inf\n",
    "best_score = 0\n",
    "optimizer = AdamW(model.parameters(), lr=CFG.lr)\n",
    "swa_scheduler = SWALR(optimizer, swa_lr=0.05)\n",
    "scheduler = get_scheduler(CFG, optimizer)\n",
    "if CFG.valid_id == None:\n",
    "    train_loader = load_data(CFG)\n",
    "else:\n",
    "    train_loader, valid_loader, valid_xyxys, valid_mask_gt = load_data(CFG)\n",
    "\n",
    "for epoch in range(CFG.epochs):\n",
    "    # train\n",
    "    avg_loss = train_fn(train_loader, model, criterion, optimizer, device)\n",
    "    if epoch > swa_start:\n",
    "        swa_model.update_parameters(model)\n",
    "        swa_scheduler.step()\n",
    "        # torch.optim.swa_utils.update_bn(train_loader, swa_model)\n",
    "        # Update bn statistics for the swa_model at the end\n",
    "    if CFG.valid_id != None:\n",
    "        # eval\n",
    "        avg_val_loss, mask_pred = valid_fn(\n",
    "            valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt)\n",
    "\n",
    "        scheduler_step(scheduler, avg_val_loss, epoch)\n",
    "\n",
    "        best_dice, best_th, best_metrics = calc_fbeta(valid_mask_gt, mask_pred)\n",
    "\n",
    "        # score = avg_val_loss\n",
    "        score = best_dice\n",
    "\n",
    "        print({\"dice\":best_dice, \"avg_train_loss\":avg_loss, \"avg_val_loss\":avg_val_loss, \"ctp\":best_metrics[0],\n",
    "                   \"cfp\":best_metrics[1], \"ctn\":best_metrics[2], \"cfn\":best_metrics[3]})\n",
    "\n",
    "        update_best = score > best_score\n",
    "        if update_best:\n",
    "            best_loss = avg_val_loss\n",
    "            best_score = score\n",
    "            best_counter = 0\n",
    "            torch.save(model.module.state_dict(),\n",
    "                    CFG.model_dir + f\"{model_name}_best.pth\")\n",
    "        else:\n",
    "            best_counter += 1\n",
    "            if best_counter > 8:\n",
    "                break\n",
    "        torch.save(model.module.state_dict(),\n",
    "                CFG.model_dir + f\"{model_name}_final.pth\")\n",
    "        plt.imshow(mask_pred > best_th)\n",
    "    else:        \n",
    "        print({\"avg_train_loss\":avg_loss})\n",
    "        scheduler_step(scheduler, avg_loss, epoch)\n",
    "        if (epoch % 5) == 0:\n",
    "            torch.save(model.module.state_dict(),\n",
    "                CFG.model_dir + f\"{model_name}_{epoch}_final.pth\")\n",
    "torch.optim.swa_utils.update_bn(train_loader, swa_model)\n",
    "torch.save(swa_model.module.state_dict(),\n",
    "    CFG.model_dir + f\"{model_name}_final_swa.pth\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d053d07861431883cae892e7b9494b3a38820803293c8494a95f4fa651f8c8c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
